\documentclass[10pt]{article}
\usepackage{kennyworkman}

\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \vphantom{\big|} % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
}}

\title{Notes on Projective Geometry}
\author{Kenny Workman}
\date{\today}

\begin{document}

\maketitle

\section{Basic Definitions}

\begin{definition}
	Let $V$ be a vector space. The projective space $P(V)$ is the set of 1-dimensional vector subspaces of $V$.
\end{definition}

It can be useful to think of projective spaces, at least in the real case, as
bundles of lines that pass through the origin. This reduces our space by a
dimension, motivating the common shorthand for the reals $P^n(R) = P(R^{n+1})$. 

Many sources encourage thinking about the sphere $S^n$ for a projective space
$P^n(\R)$ to ease the visualization of a space of lines. Antipodal points on
the sphere are identified and every such antipodal pair is injective with the
actual elements of the projective space. 

I have found it easier to just think of the vector subspaces the projective
elements represent (projective points and lines are lines and planes through the
origin in $\R^3$) for more natural geometric intuition.

\subsection{Decomposition}

The following decomposition is useful to understand the structure of theses spaces:

\[P(R^n) = R^{n-1} + P(R^{n-1}) \]

Essentially our goal is to take $R^n$ and partition the set of points into
1-dim vector subspaces such that each partition has a nice representation.
Recall:

\begin{definition}
	A representative vector is any of the non-zero vectors from the 1-dimensional subspace corresponding to a point $[v] \in P(V)$.
\end{definition}

Then if $[x] = [\lamba x] = [a]$, $x$ and $a$ are both representatives for the same projective point.

We also want to define the notion of the homogoenous coordinates for each
projective point, which are just the real points that exist in the
corresponding vector subspace.

\begin{definition}
	The homogoenous coordinates for $[v] \in P(V)$ are the set $[(x_0 \cdots x_n)]$ equivalent under scalar multiplication by $\lambda$.
\end{definition}

If we construct a subset of homogoenous coordinates $U_0$ where $x_0 \neq 1$,
notice that each $[(x_0 \cdots x_n)] = [1 \cdots x_n / x_0]$, so $U_0 \cong
R^n-1$. We are left to "partition" the coordinates where $x_0 = 0$, but this is
exactly the set of 1-dimensional subspaces of $V^n-1$, so $P(R^{n-1})$.

\subsection{Applications}


\subsection{Linear Subspaces}

We begin by proving a result from elementary linear algebra.

\begin{theorem}
	Let $W_1$ and $W_2$ be vector spaces. Then $\dim W_1 + W_2 = \dim W_1 + \dim W_2 - \dim W_1 \cap W_2$ 
\end{theorem}

\begin{proof}
	Let $S = \{ u_1 \cdots u_r \}$ be the basis of $W_1 + W_2$. Let $B_1 = \{ u_1 \cdots u_r v_1 \cdots v_s \}$ and $B_2 = \{ u_1 \cdots u_r w_1 \cdots w_t \}$ be $B$ extended to be the basis of $W_1$ and $W_2$ respectively. 
	If we can show $B$ is the basis of $W_1 + W_2$, we have our result, as $\dim B = r + s + t = (r + s) + (r + t) - r = \dim W_1 + \dim W_2 - \dim W_1 \cap W_2.$

	First, we show $B$ is linearly independent. Let 

	\[\sum_i^r{a_iu_i} + \sum_j^s{b_jv_j} + \sum_k^t{c_kw_k} = 0\]. 

	Notice if we move terms so 

	\[\sum_i^r{a_iu_i} + \sum_j^s{b_jv_j} = -\sum_k^t{c_kw_k}\], 

	then the LHS is in $W_1$ and the RHS is in $W_2$, so both sides represent the same element in $W_1 + W_2$. 

	Then $\sum_i^r{d_iu_i} = -\sum_k^t{c_kw_k}$, where the LHS uses $B$ and the RHS uses $B_2$. Again moving terms:

	\[\sum_i^r{d_iu_i} + \sum_k^t{c_kw_k} = 0\]

	Where all $c_i$ must be 0 as $B_2$ is linearly independent. Then

	\[\sum_i^r{a_iu_i} + \sum_j^s{b_jv_j} = 0\]

	But the LHS is described by $B_1$ which is also linearly independent so all $a_i$, $b_j$ must also be 0. Then $B$ is linearly independent.

	Consider any $w_1 + w_2$. 

	\[w_1 = \sum_i^r{a_iu_i} + \sum_j^s{b_jv_j}\]
	\[w_2 = \sum_i^r{d_iu_i} + \sum_k^t{c_kw_k}\]

	Then

	\[w_1 + w_2 = \sum_i^r{(a_i + d_i) u_i} + \sum_j^s{b_jv_j} + \sum_k^t{c_kw_k} \in \operatorname{span} W_1 + W_2 \]

\end{proof}

\begin{theorem}
	In a projective plane $P(V)$, two projective lines, $P(U)$ and $P(U')$, intersect in a unique point.
\end{theorem}
\begin{proof}
	From elementary linear algebra, $\dim V \geq \dim U + U'$. We have shown that $\dim U + U' = \dim U + \dim U' - \dim {U \cap U'}$.
	Then $1 \leq \dim {U \cap U'} \leq 2$. Because $P(U)$ and $P(U')$ are distinct, $\dim {U \cap U'} = 1$. So $P(U \cap U')$ is a projective point.
\end{proof}

It is useful to think about this result using our model of the projective plane as a sphere and using our decomposition.

We can think of projective lines as planes in $\R^3$ that intersect the sphere
in two great circles. These great circles intersect in a pair of antipodal
points, which is a projective line.

Alternatively

\end{document}
